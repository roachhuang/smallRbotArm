import numpy as np
import freenect
import open3d as o3d
import matplotlib.pyplot as plt
import cv2


'''
# there seems no difference if this code is run or not
# initialize Freenect
ctx = freenect.init()
# select the Kinect device
device = freenect.open_device(ctx, 0)
# set the video mode to depth
freenect.set_video_mode(
    device, freenect.RESOLUTION_MEDIUM, freenect.DEPTH_11BIT)
freenect.close_device(device)
freenect.shutdown(ctx)
'''

def get_depth():
    depth, _ = freenect.sync_get_depth()  
    #depth = depth.astype(np.uint16)
    #depth = cv2.flip(depth, 0)
    return depth

# grab a depth frame from the Kinect
# depth, timestamp = freenect.sync_get_depth()
depth = get_depth()

# convert the depth frame to a point cloud using Open3D
intrinsics = o3d.camera.PinholeCameraIntrinsic(
    640, 480, fx=594.21, fy=591.04, cx=339.5, cy=242.7)
pcd = o3d.geometry.PointCloud.create_from_depth_image(
    o3d.geometry.Image(depth), intrinsics)

origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5)


bbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=(-1, -1, -1), max_bound=(1, 1, 1))
cropped_pcd = pcd.crop(bbox)

color = [1, 0, 0] # red color
cropped_pcd.paint_uniform_color(color)
cropped_pcd.estimate_normals()

model_pcd = o3d.geometry.TriangleMesh.create_sphere(radius=0.5)
model_pcd.paint_uniform_color([0.7, 0.7, 0.7])
model_pcd.compute_vertex_normals()


# Compute normals for point cloud
# pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))

# Create Open3D mesh from point cloud and normals
# mesh, _ = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(model_pcd, depth=8)

# Visualize mesh and point cloud
#vis.add_geometry(mesh)
#vis.add_geometry(pcd)


# display the point cloud
# geometries to draw:
geometries = [pcd, origin]
o3d.visualization.draw_geometries(geometries)


